{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import io, os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! pip install librosa\n",
    "# ! pip install soundfile\n",
    "# ! pip install pyspark --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## librosa\n",
    "[librosa](https://librosa.github.io/librosa/index.html) is a Python package for music and audio processing by [Brian McFee](https://bmcfee.github.io/). A large portion was ported from [Dan Ellis's Matlab audio processing examples](http://www.ee.columbia.edu/~dpwe/resources/matlab/).\n",
    "\n",
    "If you receive an error with librosa.load, you may need to [install ffmpeg](https://librosa.github.io/librosa/install.html#ffmpeg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPython.display.Audio\n",
    "[IPython.display.Audio](https://ipython.org/ipython-doc/stable/api/generated/IPython.display.html#IPython.display.Audio) lets you play audio directly in an IPython notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Spark\n",
    "[Spark](https://spark.apache.org/docs/latest/) is used to do the parallel pre-processing of the audio data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -alh ~/vitaFlow/TEDLiumTestDataset/raw_data/train/sph/AaronHuey_2010X.sph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sph_dir = test_sph_file = os.path.expanduser(\"~\") + \"/vitaFlow/TEDLiumTestDataset/raw_data/train/sph/\"\n",
    "test_sph_file = os.path.expanduser(\"~\") + \"/vitaFlow/TEDLiumTestDataset/raw_data/train/sph/AaronHuey_2010X.sph\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the wav from binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_sph_file, mode=\"rb\") as file:\n",
    "        tmp = io.BytesIO(file.read())\n",
    "        print(tmp)\n",
    "        data, samplerate = sf.read(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate, data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(data, sr=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the Spectrum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(data)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=samplerate, x_axis='time', y_axis='hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing Audio\n",
    "Using [IPython.display.Audio](https://ipython.org/ipython-doc/2/api/generated/IPython.lib.display.html#IPython.lib.display.Audio), you can play an audio file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Preprocessing with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder. \\\n",
    "            master(\"local[4]\"). \\\n",
    "            appName(\"shabda\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wav_files_n_data = sc.binaryFiles(train_sph_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# files_bin_data = wav_files_n_data.map(lambda xy : xy).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_clips(file_path, data, num_clips=128, duration=20, output_dir=\"/tmp/\"):\n",
    "    file_path = file_path.replace(\"file:\", \"\")\n",
    "    tmp = io.BytesIO(data)\n",
    "    wav_data, sampling_rate = sf.read(tmp)\n",
    "    \n",
    "    speaker = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    speaker_dir = os.path.join(output_dir, speaker)\n",
    "    if not os.path.exists(speaker_dir):\n",
    "        os.makedirs(speaker_dir)\n",
    "\n",
    "    y, _ = librosa.load(file_path, sr=sampling_rate)\n",
    "    end_time = librosa.get_duration(y=y, sr=sampling_rate)\n",
    "    for j in range(num_clips):\n",
    "        wav_file = os.path.join(speaker_dir, str(j)) + \".wav\"\n",
    "        k = int(np.random.randint(0, end_time, size=1))\n",
    "        librosa.output.write_wav(wav_file,\n",
    "                                 y[k*sampling_rate : (k+duration)*sampling_rate],\n",
    "                                 sampling_rate)\n",
    "                    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_bin_data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to_clips(files_bin_data[0][0], files_bin_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wav_files_n_data.foreach(lambda xy : to_clips(file_path=xy[0], data=xy[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(\"1\",\"2\"),(\"1\",\"3\"),(\"2\",\"4\"),(\"4\",\"5\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = rdd.zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.map(lambda tuples : tuples[0][0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
