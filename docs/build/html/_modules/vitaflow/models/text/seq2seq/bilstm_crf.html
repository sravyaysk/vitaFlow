

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>vitaflow.models.text.seq2seq.bilstm_crf &mdash; vitaFlow 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/css/custom_theme.css" type="text/css" />
    <link rel="author" title="About these documents" href="../../../../../about.html" />
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 

  
  <script src="../../../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../../../index.html" class="icon icon-home"> vitaFlow
          

          
          </a>

          
            
            
              <div class="version">
                0.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../README.html">vitaFlow - VideoImageTextAudioFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../vitaflow_env_setup.html">vitaFlow Environment Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../vitaflow_env_setup.html#os">OS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../api/developers.html">Developers</a></li>
</ul>
<p class="caption"><span class="caption-text">API:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../api/core/core.html">Core</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../api/data/data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../api/models/models.html">Models</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../examples/conll_2003_dataset.html">CoNLL2003Dataset</a></li>
</ul>
<p class="caption"><span class="caption-text">vitaFlow Study Materials:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../dlfe/dl_for_eng.html">Deep Learning for Engineers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../audio/AudioBasics.html">Audio Basics</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">vitaFlow</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../../index.html">Module code</a> &raquo;</li>
        
      <li>vitaflow.models.text.seq2seq.bilstm_crf</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for vitaflow.models.text.seq2seq.bilstm_crf</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2018 The vitaFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#      http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">A model class that uses BiLSTM word and char level embeddings</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">overrides</span> <span class="k">import</span> <span class="n">overrides</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib.learn</span> <span class="k">import</span> <span class="n">ModeKeys</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib</span> <span class="k">import</span> <span class="n">lookup</span>

<span class="kn">from</span> <span class="nn">vitaflow.core.hyperparams</span> <span class="k">import</span> <span class="n">HParams</span>
<span class="kn">from</span> <span class="nn">vitaflow.data.text.iterators.csv_seq_to_seq_iterator</span> <span class="k">import</span> <span class="n">CSVSeqToSeqIterator</span>
<span class="kn">from</span> <span class="nn">vitaflow.data.text.vocabulary</span> <span class="k">import</span> <span class="n">SpecialTokens</span>
<span class="kn">from</span> <span class="nn">vitaflow.core.models.model_base</span> <span class="k">import</span> <span class="n">ModelBase</span>
<span class="kn">from</span> <span class="nn">vitaflow.core.features.feature_types</span> <span class="k">import</span> <span class="n">ITextFeature</span>
<span class="kn">from</span> <span class="nn">vitaflow.helpers.tf_data_helper</span> <span class="k">import</span> <span class="n">get_sequence_length</span>
<span class="kn">from</span> <span class="nn">vitaflow.helpers.print_helper</span> <span class="k">import</span> <span class="o">*</span>


<div class="viewcode-block" id="BiLSTMCrf"><a class="viewcode-back" href="../../../../../api/models/text/seq2seq/bilstm_crf.html#vitaflow.models.text.seq2seq.BiLSTMCrf">[docs]</a><span class="k">class</span> <span class="nc">BiLSTMCrf</span><span class="p">(</span><span class="n">ModelBase</span><span class="p">,</span> <span class="n">ITextFeature</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    .. code-block:: text</span>

<span class="sd">        Features : {Sentence, [character ids]}, label</span>
<span class="sd">        Word Feature Tensor</span>
<span class="sd">        Character Feature Tensor</span>
<span class="sd">        Word Embeddings Layer</span>
<span class="sd">        Character Embeddings Layer</span>
<span class="sd">        Word Level BiLSTM</span>
<span class="sd">        Character Level BiLSTM</span>
<span class="sd">        Word Level BiLSTM Output + Character Level BiLSTM</span>
<span class="sd">        Fully Connected Layer</span>
<span class="sd">        CRF Loss</span>
<span class="sd">        Classes and Probability Predictions</span>


<span class="sd">    References:</span>
<span class="sd">        - https://github.com/guillaumegenthial/sequence_tagging</span>
<span class="sd">        - https://github.com/jiaqianghuai/tf-lstm-crf-batch</span>
<span class="sd">        - https://www.tensorflow.org/api_docs/python/tf/contrib/crf</span>
<span class="sd">        - https://github.com/Franck-Dernoncourt/NeuroNER</span>
<span class="sd">        - https://www.clips.uantwerpen.be/conll2003/ner/</span>
<span class="sd">        - https://stackoverflow.com/questions/3330227/free-tagged-corpus-for-named-entity-recognition</span>

<span class="sd">        - https://sites.google.com/site/ermasoftware/getting-started/ne-tagging-conll2003-data</span>
<span class="sd">        - Dataset: https://github.com/synalp/NER/tree/master/corpus/CoNLL-2003</span>
<span class="sd">        - Reference: https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/examples/tutorials/estimators/abalone.py</span>
<span class="sd">        - https://github.com/tensorflow/tensorflow/issues/14018</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data_iterator</span><span class="p">:</span> <span class="n">CSVSeqToSeqIterator</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">ITextFeature</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">ModelBase</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hparams</span> <span class="o">=</span> <span class="n">HParams</span><span class="p">(</span><span class="n">hparams</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">default_hparams</span><span class="p">())</span>

        <span class="c1"># if not isinstance(data_iterator, CoNLLCsvDataIterator):</span>
        <span class="c1">#     raise RuntimeError</span>

        <span class="c1"># Constant params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">UNKNOWN_WORD</span> <span class="o">=</span> <span class="n">SpecialTokens</span><span class="o">.</span><span class="n">UNK_WORD</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">PAD_WORD</span> <span class="o">=</span> <span class="n">SpecialTokens</span><span class="o">.</span><span class="n">PAD_WORD</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">SEPERATOR</span> <span class="o">=</span> <span class="s2">&quot;~&quot;</span>

        <span class="c1"># Preprocessing Paramaters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">TAGS_VOCAB_FILE</span> <span class="o">=</span> <span class="n">data_iterator</span><span class="o">.</span><span class="n">ENTITY_VOCAB_FILE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">WORDS_VOCAB_FILE</span> <span class="o">=</span> <span class="n">data_iterator</span><span class="o">.</span><span class="n">WORDS_VOCAB_FILE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CHARS_VOCAB_FILE</span> <span class="o">=</span> <span class="n">data_iterator</span><span class="o">.</span><span class="n">CHARS_VOCAB_FILE</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">VOCAB_SIZE</span> <span class="o">=</span> <span class="n">data_iterator</span><span class="o">.</span><span class="n">word_vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CHAR_VOCAB_SIZE</span> <span class="o">=</span> <span class="n">data_iterator</span><span class="o">.</span><span class="n">char_vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">NUM_TAGS</span> <span class="o">=</span> <span class="n">data_iterator</span><span class="o">.</span><span class="n">num_lables</span>

        <span class="c1"># Model hyper parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">USE_CHAR_EMBEDDING</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hparams</span><span class="o">.</span><span class="n">use_char_embd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hparams</span><span class="o">.</span><span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">KEEP_PROP</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hparams</span><span class="o">.</span><span class="n">keep_propability</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">WORD_EMBEDDING_SIZE</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hparams</span><span class="o">.</span><span class="n">word_emd_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CHAR_EMBEDDING_SIZE</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hparams</span><span class="o">.</span><span class="n">char_emd_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">WORD_LEVEL_LSTM_HIDDEN_SIZE</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hparams</span><span class="o">.</span><span class="n">word_level_lstm_hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CHAR_LEVEL_LSTM_HIDDEN_SIZE</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hparams</span><span class="o">.</span><span class="n">char_level_lstm_hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">NUM_LSTM_LAYERS</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hparams</span><span class="o">.</span><span class="n">num_lstm_layers</span>

<div class="viewcode-block" id="BiLSTMCrf.default_hparams"><a class="viewcode-back" href="../../../../../api/models/text/seq2seq/bilstm_crf.html#vitaflow.models.text.seq2seq.BiLSTMCrf.default_hparams">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">default_hparams</span><span class="p">():</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        .. role:: python(code)</span>
<span class="sd">           :language: python</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            {</span>
<span class="sd">                &quot;model_root_directory&quot; : os.path.expanduser(&quot;~&quot;) + &quot;/vitaFlow/&quot;,</span>
<span class="sd">                &quot;experiment_name&quot; : &quot;experiment_name&quot;,</span>
<span class="sd">                # hyper parameters</span>
<span class="sd">                &quot;use_char_embd&quot;: False,</span>
<span class="sd">                &quot;learning_rate&quot;: 0.001,</span>
<span class="sd">                &quot;word_level_lstm_hidden_size&quot;: 24,</span>
<span class="sd">                &quot;char_level_lstm_hidden_size&quot;: 24,</span>
<span class="sd">                &quot;word_emd_size&quot;: 24,</span>
<span class="sd">                &quot;char_emd_size&quot;: 24,</span>
<span class="sd">                &quot;num_lstm_layers&quot;: 1,</span>
<span class="sd">                &quot;keep_probability&quot;: 0.5,</span>
<span class="sd">            }</span>

<span class="sd">        Here:</span>

<span class="sd">        &quot;use_char_embd&quot; : boolean</span>
<span class="sd">            Use character level embedding as part of the model</span>

<span class="sd">        &quot;learning_rate&quot; : float</span>
<span class="sd">            Learning rate</span>

<span class="sd">        &quot;word_level_lstm_hidden_size&quot; : int</span>
<span class="sd">            Word layer LSTM hidden size</span>

<span class="sd">        &quot;char_level_lstm_hidden_size&quot; : int</span>
<span class="sd">            Character layer LSTM hidden size</span>

<span class="sd">        &quot;word_emd_size&quot; : int</span>
<span class="sd">            Word embedding size</span>

<span class="sd">        &quot;char_emd_size&quot; : int</span>
<span class="sd">            Character embedding size</span>

<span class="sd">        &quot;num_lstm_layers&quot; : int</span>
<span class="sd">            Number of LSTM layer</span>

<span class="sd">        &quot;keep_propability&quot; : float</span>
<span class="sd">            Drop out layer `keep` probability value</span>

<span class="sd">        :return: A dictionary of hyperparameters with default values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">hparams</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;model_root_directory&quot;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s2">&quot;~&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;/vitaFlow/&quot;</span><span class="p">,</span>
            <span class="s2">&quot;experiment_name&quot;</span><span class="p">:</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
            <span class="c1"># hyper parameters</span>
            <span class="s2">&quot;use_char_embd&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
            <span class="s2">&quot;word_level_lstm_hidden_size&quot;</span><span class="p">:</span> <span class="mi">24</span><span class="p">,</span>
            <span class="s2">&quot;char_level_lstm_hidden_size&quot;</span><span class="p">:</span> <span class="mi">24</span><span class="p">,</span>
            <span class="s2">&quot;word_emd_size&quot;</span><span class="p">:</span> <span class="mi">24</span><span class="p">,</span>
            <span class="s2">&quot;char_emd_size&quot;</span><span class="p">:</span> <span class="mi">24</span><span class="p">,</span>
            <span class="s2">&quot;num_lstm_layers&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;keep_probability&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="p">}</span></div>
        <span class="k">return</span> <span class="n">hparams</span>


    <span class="k">def</span> <span class="nf">_build_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>

        <span class="n">is_training</span> <span class="o">=</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span>

        <span class="c1"># [BATCH_SIZE, 1]</span>
        <span class="n">text_features</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">FEATURE_1_NAME</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">USE_CHAR_EMBEDDING</span><span class="p">:</span>
            <span class="c1"># [BATCH_SIZE, MAX_SEQ_LENGTH, MAX_WORD_LEGTH]</span>
            <span class="n">char_ids</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">FEATURE_2_NAME</span><span class="p">]</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;char_ids: =======&gt; </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">char_ids</span><span class="p">))</span>

            <span class="n">s</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">char_ids</span><span class="p">)</span>

            <span class="c1"># remove pad words</span>
            <span class="n">char_ids_reshaped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">char_ids</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>  <span class="c1"># 20 -&gt; char dim</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;sentence-words-2-ids&quot;</span><span class="p">):</span>
            <span class="n">word_table</span> <span class="o">=</span> <span class="n">lookup</span><span class="o">.</span><span class="n">index_table_from_file</span><span class="p">(</span><span class="n">vocabulary_file</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">WORDS_VOCAB_FILE</span><span class="p">,</span>
                                                      <span class="n">num_oov_buckets</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># TODO use this for Out of Vocab</span>
                                                      <span class="n">default_value</span><span class="o">=</span><span class="n">SpecialTokens</span><span class="o">.</span><span class="n">UNK_WORD_ID</span><span class="p">,</span>
                                                      <span class="c1"># id of &lt;UNK&gt;  w.r.t WORD VOCAB</span>
                                                      <span class="n">name</span><span class="o">=</span><span class="s2">&quot;table&quot;</span><span class="p">)</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;word_table info: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">word_table</span><span class="p">))</span>

            <span class="c1"># [BATCH_SIZE, 1]</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">string_split</span><span class="p">(</span><span class="n">text_features</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">SEPERATOR</span><span class="p">)</span>

            <span class="c1"># [BATCH_SIZE, ?] i.e [BATCH_SIZE, VARIABLE_SEQ_LENGTH]</span>
            <span class="n">densewords</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse_tensor_to_dense</span><span class="p">(</span><span class="n">words</span><span class="p">,</span>
                                                   <span class="n">default_value</span><span class="o">=</span><span class="n">SpecialTokens</span><span class="o">.</span><span class="n">PAD_WORD</span><span class="p">)</span>  <span class="c1"># TODO add test case</span>

            <span class="c1"># [BATCH_SIZE, ?] i.e [BATCH_SIZE, MAX_SEQ_LENGTH]</span>
            <span class="n">token_ids</span> <span class="o">=</span> <span class="n">word_table</span><span class="o">.</span><span class="n">lookup</span><span class="p">(</span><span class="n">densewords</span><span class="p">)</span>  <span class="c1"># TODO check is it variable length or not?</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;word-embed-layer&quot;</span><span class="p">):</span>
            <span class="c1"># layer to take the words and convert_image them into vectors (embeddings)</span>
            <span class="c1"># This creates embeddings matrix of [VOCAB_SIZE, EMBEDDING_SIZE] and then</span>
            <span class="c1"># maps word indexes of the sequence into</span>
            <span class="c1"># [BATCH_SIZE, MAX_SEQ_LENGTH] ---&gt;  [BATCH_SIZE, MAX_SEQ_LENGTH, WORD_EMBEDDING_SIZE].</span>
            <span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">token_ids</span><span class="p">,</span>
                                                               <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">VOCAB_SIZE</span><span class="p">,</span>
                                                               <span class="n">embed_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">WORD_EMBEDDING_SIZE</span><span class="p">,</span>
                                                               <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">(</span>
                                                                   <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>

            <span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">word_embeddings</span><span class="p">,</span>
                                                <span class="n">rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">KEEP_PROP</span><span class="p">,</span>
                                                <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                                                <span class="n">training</span><span class="o">=</span><span class="n">mode</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">)</span>

            <span class="c1"># [BATCH_SIZE, MAX_SEQ_LENGTH, WORD_EMBEDDING_SIZE]</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;word_embeddings =====&gt; </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">word_embeddings</span><span class="p">))</span>

            <span class="c1"># seq_length = get_sequence_length_old(word_embeddings) TODO working</span>
            <span class="c1"># [BATCH_SIZE, ]</span>
            <span class="n">seq_length</span> <span class="o">=</span> <span class="n">get_sequence_length</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seq_length</span> <span class="o">=</span> <span class="n">seq_length</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;seq_length =====&gt; </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">seq_length</span><span class="p">))</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;char_embed_layer&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">USE_CHAR_EMBEDDING</span><span class="p">:</span>
                <span class="n">print_error</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">CHAR_VOCAB_SIZE</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">CHAR_EMBEDDING_SIZE</span><span class="p">))</span>
                <span class="n">char_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">char_ids</span><span class="p">,</span>
                                                                   <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">CHAR_VOCAB_SIZE</span><span class="p">,</span>
                                                                   <span class="n">embed_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">CHAR_EMBEDDING_SIZE</span><span class="p">,</span>
                                                                   <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">(</span>
                                                                       <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>

                <span class="c1"># [BATCH_SIZE, MAX_SEQ_LENGTH, MAX_WORD_LEGTH, CHAR_EMBEDDING_SIZE]</span>
                <span class="n">char_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">char_embeddings</span><span class="p">,</span>
                                                    <span class="n">rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">KEEP_PROP</span><span class="p">,</span>
                                                    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                                                    <span class="n">training</span><span class="o">=</span><span class="n">mode</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">)</span>  <span class="c1"># TODO add test case</span>

                <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;char_embeddings =====&gt; </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">char_embeddings</span><span class="p">))</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;chars_level_bilstm_layer&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">USE_CHAR_EMBEDDING</span><span class="p">:</span>
                <span class="c1"># put the time dimension on axis=1</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">char_embeddings</span><span class="p">)</span>

                <span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">MAX_DOC_LENGTH</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">CHAR_MAX_LENGTH</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

                <span class="n">TOTAL_DOCS_LENGTH</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">seq_length</span><span class="p">)</span>

                <span class="c1"># [BATCH_SIZE, MAX_SEQ_LENGTH, MAX_WORD_LEGTH, CHAR_EMBEDDING_SIZE]  ===&gt;</span>
                <span class="c1">#      [BATCH_SIZE * MAX_SEQ_LENGTH, MAX_WORD_LEGTH, CHAR_EMBEDDING_SIZE]</span>
                <span class="n">char_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">char_embeddings</span><span class="p">,</span>
                                             <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">BATCH_SIZE</span> <span class="o">*</span> <span class="n">MAX_DOC_LENGTH</span><span class="p">,</span> <span class="n">CHAR_MAX_LENGTH</span><span class="p">,</span>
                                                    <span class="bp">self</span><span class="o">.</span><span class="n">CHAR_EMBEDDING_SIZE</span><span class="p">],</span>
                                             <span class="n">name</span><span class="o">=</span><span class="s2">&quot;reduce_dimension_1&quot;</span><span class="p">)</span>

                <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;reshaped char_embeddings =====&gt; </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">char_embeddings</span><span class="p">))</span>

                <span class="c1"># word_lengths = get_sequence_length_old(char_embeddings) TODO working</span>
                <span class="n">word_lengths</span> <span class="o">=</span> <span class="n">get_sequence_length</span><span class="p">(</span><span class="n">char_ids_reshaped</span><span class="p">)</span>

                <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;word_lengths =====&gt; </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">word_lengths</span><span class="p">))</span>

                <span class="c1"># bi lstm on chars</span>
                <span class="n">cell_fw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">CHAR_LEVEL_LSTM_HIDDEN_SIZE</span><span class="p">,</span>
                                                  <span class="n">state_is_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">cell_bw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">CHAR_LEVEL_LSTM_HIDDEN_SIZE</span><span class="p">,</span>
                                                  <span class="n">state_is_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                <span class="n">_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bidirectional_dynamic_rnn</span><span class="p">(</span>
                    <span class="n">cell_fw</span><span class="o">=</span><span class="n">cell_fw</span><span class="p">,</span>
                    <span class="n">cell_bw</span><span class="o">=</span><span class="n">cell_bw</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                    <span class="n">sequence_length</span><span class="o">=</span><span class="n">word_lengths</span><span class="p">,</span>
                    <span class="n">inputs</span><span class="o">=</span><span class="n">char_embeddings</span><span class="p">,</span>
                    <span class="n">scope</span><span class="o">=</span><span class="s2">&quot;encode_words&quot;</span><span class="p">)</span>

                <span class="c1"># read and concat output</span>
                <span class="n">_</span><span class="p">,</span> <span class="p">((</span><span class="n">_</span><span class="p">,</span> <span class="n">output_fw</span><span class="p">),</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">output_bw</span><span class="p">))</span> <span class="o">=</span> <span class="n">_output</span>
                <span class="n">encoded_words</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">output_fw</span><span class="p">,</span> <span class="n">output_bw</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

                <span class="c1"># [BATCH_SIZE, MAX_SEQ_LENGTH, WORD_EMBEDDING_SIZE]</span>
                <span class="n">encoded_words</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">encoded_words</span><span class="p">,</span>
                                           <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">MAX_DOC_LENGTH</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span>
                                                  <span class="bp">self</span><span class="o">.</span><span class="n">CHAR_LEVEL_LSTM_HIDDEN_SIZE</span><span class="p">])</span>

                <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;encoded_words =====&gt; </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">encoded_words</span><span class="p">))</span>

        <span class="k">with</span>  <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;word_level_lstm_layer&quot;</span><span class="p">):</span>
            <span class="c1"># Create a LSTM Unit cell with hidden size of EMBEDDING_SIZE.</span>
            <span class="n">d_rnn_cell_fw_one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">WORD_LEVEL_LSTM_HIDDEN_SIZE</span><span class="p">,</span>
                                                        <span class="n">state_is_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">d_rnn_cell_bw_one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">WORD_LEVEL_LSTM_HIDDEN_SIZE</span><span class="p">,</span>
                                                        <span class="n">state_is_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">is_training</span><span class="p">:</span>
                <span class="n">d_rnn_cell_fw_one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">d_rnn_cell_fw_one</span><span class="p">,</span>
                                                                  <span class="n">output_keep_prob</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">KEEP_PROP</span><span class="p">)</span>
                <span class="n">d_rnn_cell_bw_one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">d_rnn_cell_bw_one</span><span class="p">,</span>
                                                                  <span class="n">output_keep_prob</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">KEEP_PROP</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">d_rnn_cell_fw_one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">d_rnn_cell_fw_one</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
                <span class="n">d_rnn_cell_bw_one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">d_rnn_cell_bw_one</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

            <span class="n">d_rnn_cell_fw_one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">(</span><span class="n">cells</span><span class="o">=</span><span class="p">[</span><span class="n">d_rnn_cell_fw_one</span><span class="p">]</span> <span class="o">*</span>
                                                                  <span class="bp">self</span><span class="o">.</span><span class="n">NUM_LSTM_LAYERS</span><span class="p">,</span>
                                                            <span class="n">state_is_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">d_rnn_cell_bw_one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">(</span><span class="n">cells</span><span class="o">=</span><span class="p">[</span><span class="n">d_rnn_cell_bw_one</span><span class="p">]</span> <span class="o">*</span>
                                                                  <span class="bp">self</span><span class="o">.</span><span class="n">NUM_LSTM_LAYERS</span><span class="p">,</span>
                                                            <span class="n">state_is_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="p">(</span><span class="n">fw_output_one</span><span class="p">,</span> <span class="n">bw_output_one</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bidirectional_dynamic_rnn</span><span class="p">(</span>
                <span class="n">cell_fw</span><span class="o">=</span><span class="n">d_rnn_cell_fw_one</span><span class="p">,</span>
                <span class="n">cell_bw</span><span class="o">=</span><span class="n">d_rnn_cell_bw_one</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                <span class="n">sequence_length</span><span class="o">=</span><span class="n">seq_length</span><span class="p">,</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">word_embeddings</span><span class="p">,</span>
                <span class="n">scope</span><span class="o">=</span><span class="s2">&quot;encod_sentence&quot;</span><span class="p">)</span>

            <span class="c1"># [BATCH_SIZE, MAX_SEQ_LENGTH, 2*WORD_LEVEL_LSTM_HIDDEN_SIZE) TODO check MAX_SEQ_LENGTH?</span>
            <span class="n">encoded_sentence</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fw_output_one</span><span class="p">,</span>
                                          <span class="n">bw_output_one</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;encoded_sentence =====&gt; </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">encoded_sentence</span><span class="p">))</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;char_word_embeddings-mergeing_layer&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">USE_CHAR_EMBEDDING</span><span class="p">:</span>
                <span class="n">encoded_doc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">encoded_words</span><span class="p">,</span> <span class="n">encoded_sentence</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;sentence_words_concat&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">encoded_doc</span> <span class="o">=</span> <span class="n">encoded_sentence</span>

            <span class="c1"># [BATCH_SIZE, MAX_SEQ_LENGTH, 2*WORD_LEVEL_LSTM_HIDDEN_SIZE + 2*CHAR_LEVEL_LSTM_HIDDEN_SIZE]</span>
            <span class="n">encoded_doc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">encoded_doc</span><span class="p">,</span>
                                            <span class="n">rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">KEEP_PROP</span><span class="p">,</span>
                                            <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                                            <span class="n">training</span><span class="o">=</span><span class="n">mode</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">)</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;encoded_doc: =====&gt; </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">encoded_doc</span><span class="p">))</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;projection&quot;</span><span class="p">):</span>

            <span class="n">NUM_WORD_LSTM_NETWORKS</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># word_level_lstm_layer BiDirectional</span>
            <span class="n">NUM_CHAR_LSTM_NETWORKS</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># char_level_lstm_layer BiDirectional</span>

            <span class="c1"># Example: If WORD_LEVEL_LSTM_HIDDEN_SIZE = 300, CHAR_LEVEL_LSTM_HIDDEN_SIZE = 300,</span>
            <span class="c1"># NEW_SHAPE = 2 * 300 + 2 * 300 = 1200</span>
            <span class="n">NEW_SHAPE</span> <span class="o">=</span> <span class="n">NUM_WORD_LSTM_NETWORKS</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">WORD_LEVEL_LSTM_HIDDEN_SIZE</span> <span class="o">+</span> \
                        <span class="n">NUM_CHAR_LSTM_NETWORKS</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">CHAR_LEVEL_LSTM_HIDDEN_SIZE</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">USE_CHAR_EMBEDDING</span><span class="p">:</span>
                <span class="c1"># [NEW_SHAPE, NUM_TAGS]</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">&quot;W&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                                    <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">NEW_SHAPE</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">NUM_TAGS</span><span class="p">])</span>
                <span class="c1"># [NUM_TAGS]</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">NUM_TAGS</span><span class="p">],</span>
                                    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># [NUM_WORD_LSTM_NETWORKS * WORD_LEVEL_LSTM_HIDDEN_SIZE, NUM_TAGS]</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">&quot;W&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                                    <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">NUM_WORD_LSTM_NETWORKS</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">WORD_LEVEL_LSTM_HIDDEN_SIZE</span><span class="p">,</span>
                                           <span class="bp">self</span><span class="o">.</span><span class="n">NUM_TAGS</span><span class="p">])</span>
                <span class="c1"># [NUM_TAGS]</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">NUM_TAGS</span><span class="p">],</span>
                                    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">())</span>
            <span class="c1"># [MAX_SEQ_LENGTH]</span>
            <span class="n">nsteps</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoded_doc</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;nsteps: =====&gt; </span><span class="si">{}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nsteps</span><span class="p">))</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">USE_CHAR_EMBEDDING</span><span class="p">:</span>
                <span class="n">encoded_doc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">encoded_doc</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">NEW_SHAPE</span><span class="p">],</span>
                                         <span class="n">name</span><span class="o">=</span><span class="s2">&quot;reshape_encoded_doc&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">encoded_doc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">encoded_doc</span><span class="p">,</span>
                                         <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">NUM_WORD_LSTM_NETWORKS</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">WORD_LEVEL_LSTM_HIDDEN_SIZE</span><span class="p">],</span>
                                         <span class="n">name</span><span class="o">=</span><span class="s2">&quot;reshape_encoded_doc&quot;</span><span class="p">)</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;encoded_doc: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">encoded_doc</span><span class="p">))</span>
            <span class="n">encoded_doc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">encoded_doc</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;encoded_doc: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">encoded_doc</span><span class="p">))</span>
            <span class="c1"># [BATCH_SIZE, MAX_SEQ_LENGTH, NUM_TAGS]</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">encoded_doc</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">nsteps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">NUM_TAGS</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;reshape_predictions&quot;</span><span class="p">)</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;logits: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logits</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">logits</span>

    <span class="k">def</span> <span class="nf">_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
        <span class="k">with</span>  <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;loss-layer&quot;</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Defines the loss&quot;&quot;&quot;</span>

            <span class="c1"># if mode == ModeKeys.INFER:</span>
            <span class="c1">#     ner_ids = tf.placeholder(tf.int32, shape=[None, None],</span>
            <span class="c1">#                              name=&quot;labels&quot;)  # no labels during prediction</span>
            <span class="c1"># else:</span>
            <span class="n">ner_ids</span> <span class="o">=</span> <span class="n">labels</span>

            <span class="n">print_error</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seq_length</span><span class="p">)</span>
            <span class="n">print_error</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
            <span class="n">print_error</span><span class="p">(</span><span class="n">ner_ids</span><span class="p">)</span>
            <span class="n">log_likelihood</span><span class="p">,</span> <span class="n">trans_params</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">crf</span><span class="o">.</span><span class="n">crf_log_likelihood</span><span class="p">(</span>
                <span class="n">logits</span><span class="p">,</span> <span class="n">ner_ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_length</span><span class="p">)</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;log_likelihood:  =====&gt; </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">log_likelihood</span><span class="p">))</span>

            <span class="c1"># [NUM_TAGS, NUM_TAGS]</span>
            <span class="n">trans_params</span> <span class="o">=</span> <span class="n">trans_params</span>  <span class="c1"># need to evaluate it for decoding</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;trans_params: =====&gt; </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trans_params</span><span class="p">))</span>
            <span class="n">ner_crf_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">log_likelihood</span><span class="p">)</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">ner_crf_loss</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">ner_crf_loss</span><span class="p">,</span> <span class="n">trans_params</span>

    <span class="k">def</span> <span class="nf">_get_predictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">trans_params</span><span class="p">):</span>
        <span class="n">viterbi_seq</span><span class="p">,</span> <span class="n">best_score</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">crf</span><span class="o">.</span><span class="n">crf_decode</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">trans_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_length</span><span class="p">)</span>

        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;viterbi_seq: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">viterbi_seq</span><span class="p">))</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="p">{</span>  <span class="c1"># TODO features class</span>
            <span class="s2">&quot;classes&quot;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
                               <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
            <span class="c1"># [BATCH_SIZE, SEQ_LEN]</span>
            <span class="s2">&quot;viterbi_seq&quot;</span><span class="p">:</span> <span class="n">viterbi_seq</span><span class="p">,</span>
            <span class="c1"># [BATCH_SIZE]</span>
            <span class="s2">&quot;confidence&quot;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>

            <span class="s2">&quot;top_3_indices&quot;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span>

            <span class="s2">&quot;top_3_confidence&quot;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">predictions</span>

    <span class="k">def</span> <span class="nf">_get_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">optimize_loss</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">global_step</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_global_step</span><span class="p">(),</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">LEARNING_RATE</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">train_op</span>

    <span class="k">def</span> <span class="nf">_get_eval_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span>
                <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                <span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">[</span><span class="s2">&quot;viterbi_seq&quot;</span><span class="p">],</span>
                <span class="n">name</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">),</span>
            <span class="s1">&#39;Precision&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">precision</span><span class="p">(</span>
                <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                <span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">[</span><span class="s2">&quot;viterbi_seq&quot;</span><span class="p">],</span>
                <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Precision&#39;</span><span class="p">),</span>
            <span class="s1">&#39;Recall&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">recall</span><span class="p">(</span>
                <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                <span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">[</span><span class="s2">&quot;viterbi_seq&quot;</span><span class="p">],</span>
                <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Recall&#39;</span><span class="p">)</span>
        <span class="p">}</span>

    <span class="nd">@overrides</span>
    <span class="k">def</span> <span class="nf">_build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="c1"># Loss, training and eval operations are not needed during inference.</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">eval_metric_ops</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;ner-tags-2-ids&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">!=</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">INFER</span><span class="p">:</span>
                <span class="n">ner_table</span> <span class="o">=</span> <span class="n">lookup</span><span class="o">.</span><span class="n">index_table_from_file</span><span class="p">(</span><span class="n">vocabulary_file</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">TAGS_VOCAB_FILE</span><span class="p">,</span>
                                                         <span class="n">num_oov_buckets</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                                         <span class="n">default_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># id of &lt;UNK&gt; w.r.t ENTITY VOCAB</span>
                                                         <span class="n">name</span><span class="o">=</span><span class="s2">&quot;table&quot;</span><span class="p">)</span>

                <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;ner_table info: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ner_table</span><span class="p">))</span>

                <span class="c1"># [BATCH_SIZE, 1]</span>
                <span class="n">labels_splitted</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">string_split</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">SEPERATOR</span><span class="p">)</span>
                <span class="c1"># [BATCH_SIZE, ?] i.e [BATCH_SIZE, VARIABLE_SEQ_LENGTH]</span>
                <span class="n">labels_splitted_dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse_tensor_to_dense</span><span class="p">(</span><span class="n">labels_splitted</span><span class="p">,</span>
                                                                  <span class="n">default_value</span><span class="o">=</span><span class="s2">&quot;O&quot;</span><span class="p">)</span>
                <span class="c1"># [BATCH_SIZE, ?] i.e [BATCH_SIZE, MAX_SEQ_LENGTH]</span>
                <span class="n">ner_ids</span> <span class="o">=</span> <span class="n">ner_table</span><span class="o">.</span><span class="n">lookup</span><span class="p">(</span><span class="n">labels_splitted_dense</span><span class="p">)</span>
                <span class="n">ner_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">ner_ids</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

                <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;ner_ids: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ner_ids</span><span class="p">))</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_layers</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">INFER</span><span class="p">:</span>
            <span class="n">ner_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
                                     <span class="n">name</span><span class="o">=</span><span class="s2">&quot;labels&quot;</span><span class="p">)</span>  <span class="c1"># no labels during prediction</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ner_ids</span> <span class="o">=</span> <span class="n">ner_ids</span>

        <span class="n">log_likelihood</span><span class="p">,</span> <span class="n">trans_params</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">crf</span><span class="o">.</span><span class="n">crf_log_likelihood</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span> <span class="n">ner_ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_length</span><span class="p">)</span>

        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;log_likelihood:  =====&gt; </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">log_likelihood</span><span class="p">))</span>

        <span class="c1"># [NUM_TAGS, NUM_TAGS]</span>
        <span class="n">trans_params</span> <span class="o">=</span> <span class="n">trans_params</span>  <span class="c1"># need to evaluate it for decoding</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;trans_params: =====&gt; </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trans_params</span><span class="p">))</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_predictions</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">trans_params</span><span class="o">=</span><span class="n">trans_params</span><span class="p">)</span>

        <span class="n">eval_metric_ops</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">!=</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">:</span>
            <span class="c1"># labels = tf.reshape(labels, shape=(-1, self._out_dim), name=&quot;labels&quot;)</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;labels: -----&gt; </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ner_ids</span><span class="p">))</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">log_likelihood</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;crf_loss&quot;</span><span class="p">)</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_optimizer</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="n">eval_metric_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_eval_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">ner_ids</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">EstimatorSpec</span><span class="p">(</span>
            <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
            <span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">train_op</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span></div>
            <span class="n">eval_metric_ops</span><span class="o">=</span><span class="n">eval_metric_ops</span><span class="p">)</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, vitaFlow Team

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../../../../../',
              VERSION:'0.0.1',
              LANGUAGE:'None',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>